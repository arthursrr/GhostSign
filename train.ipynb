{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from datetime import datetime\n",
    "import uuid\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from HiDDeN import HiDDeN\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "datadir = './data/voc'\n",
    "trainingset = datadir + '/train/'\n",
    "testset = datadir + '/tester/'\n",
    "\n",
    "BATCH_SIZE = 20\n",
    "KERNEL_SIZE = 3\n",
    "IMAGE_SIZE = 128\n",
    "CHANNEL = 3\n",
    "\n",
    "EVAL_STEP = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2501 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "\t\tdirectory=trainingset,\n",
    "\t\ttarget_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "\t\tcolor_mode=\"rgb\",\n",
    "\t\tbatch_size=BATCH_SIZE,\n",
    "\t\tclass_mode=\"input\",\n",
    "\t\tshuffle=False\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4952 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_datagen.flow_from_directory(\n",
    "\t\tdirectory=testset,\n",
    "\t\ttarget_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "\t\tcolor_mode=\"rgb\",\n",
    "\t\tbatch_size=BATCH_SIZE,\n",
    "\t\tclass_mode=\"input\",\n",
    "\t\tshuffle=False,\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image input (128, 128, 3)\n",
      "Loaded 2501 training samples\n",
      "Loaded 4952 test samples\n"
     ]
    }
   ],
   "source": [
    "print(f\"Image input {train_generator.image_shape}\")\n",
    "print(f'Loaded {train_generator.n} training samples')\n",
    "print(f'Loaded {test_generator.n} test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(list1):\n",
    "\t# insert the list to the set\n",
    "\tlist_set = set(list1)\n",
    "\t# convert the set to the list\n",
    "\tunique_list = (list(list_set))\n",
    "\tres = []\n",
    "\tfor x in unique_list:\n",
    "\t\tres.append(x)\n",
    "\treturn res\n",
    "\n",
    "\n",
    "def string_to_binary(string):\n",
    "\tbinary_message = ''.join(format(i, '08b') for i in bytearray(string, encoding ='utf-8'))\n",
    "\treturn binary_message\n",
    "\n",
    "\n",
    "def generate_random_messages(N):\n",
    "\tmessage_string = []\n",
    "\tmessages_binary = []\n",
    "\tmessages_tensor = None\n",
    "\tfor _ in range(N):\n",
    "\t\ttext = uuid.uuid4().hex\n",
    "\t\tbinary_message = string_to_binary(text)\n",
    "\t\tmessage_array = [float(x) for x in binary_message]\n",
    "\t\tmessage_ts = tf.constant(message_array)\n",
    "\t\tmessage_ts = tf.reshape(message_ts, (16,16,1))\n",
    "\t\tmessage_ts = tf.expand_dims(message_ts, axis=0)\n",
    "\t\t\n",
    "\t\tmessage_string.append(text)\n",
    "\t\tmessages_binary.append(message_array)\n",
    "\t\tif messages_tensor is None:\n",
    "\t\t\tmessages_tensor = message_ts\n",
    "\t\telse:\n",
    "\t\t\tmessages_tensor = tf.concat([messages_tensor, message_ts], axis=0)\n",
    "\n",
    "\treturn (message_string, tf.constant(messages_binary), messages_tensor)\n",
    "\n",
    "\n",
    "def decode_binary_string(s):\n",
    "    byte_string = ''.join(chr(int(s[i*8:i*8+8],2)) for i in range(len(s)//8))\n",
    "    return byte_string.encode().decode('utf-8')\n",
    "\n",
    "\n",
    "def round_predicted_message(predicted_message):\n",
    "    rounded_message = ''\n",
    "    for num in predicted_message:\n",
    "        if(float(num) > 0.5):\n",
    "            rounded_message += '1'\n",
    "        else:\n",
    "            rounded_message += '0'\n",
    "    return rounded_message\n",
    "\n",
    "\n",
    "def count_errors(original_message, predicted_message):\n",
    "    original_message = round_predicted_message(original_message)\n",
    "    count = 0\n",
    "    for i in range(len(original_message)):\n",
    "        if original_message[i] != predicted_message[i]:\n",
    "            count += 1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2501, 128, 128, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_shape = train_generator.image_shape\n",
    "(N, H, W, C) = (train_generator.n, input_shape[0], input_shape[1], input_shape[2])\n",
    "(N, H, W, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(msg_str, msg_array, msg_tensor) = generate_random_messages(N)\n",
    "len(unique(msg_str)) == len(msg_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = msg_array.shape[1]\n",
    "L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2501 images, 128 x 128 x 3\n",
      "Message length: 256\n"
     ]
    }
   ],
   "source": [
    "print(f'{N} images, {H} x {W} x {C}')\n",
    "print(f\"Message length: {L}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HiDDeN(\n",
    "\timg_shape=(IMAGE_SIZE, IMAGE_SIZE, CHANNEL), \n",
    "\tmsg_shape=(msg_tensor.shape[1],msg_tensor.shape[2], msg_tensor.shape[3]),\n",
    "\tkernel_size=KERNEL_SIZE,\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(msg_str_test, msg_array_test, msg_tensor_test) = generate_random_messages(test_generator.n)\n",
    "len(unique(msg_str_test)) == len(msg_str_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = model.Generator()\n",
    "discriminator = model.Discriminator()\n",
    "reader = model.Reader()\n",
    "\n",
    "generator_loss = model.generator_loss\n",
    "discriminator_loss = model.discriminator_loss\n",
    "\n",
    "generator_optimizer = Adam(2e-4, beta_1=0.5)\n",
    "discriminator_optimizer = Adam(2e-4, beta_1=0.5)\n",
    "reader_optimizer = Adam(2e-4, beta_1=0.5)\n",
    "\t\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n",
    "checkpoint = tf.train.Checkpoint(\n",
    "                        generator_optimizer=generator_optimizer,\n",
    "                        discriminator_optimizer=discriminator_optimizer,\n",
    "                        generator=generator,\n",
    "                        discriminator=discriminator,\n",
    "            )\n",
    "\n",
    "log_dir=\"logs/\"\n",
    "\n",
    "summary_writer = tf.summary.create_file_writer(\n",
    "\tlog_dir + \"fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_images(img_model, msg_model, input_img, input_msg, target_msg, target_str):\n",
    "    img_pred = img_model([tf.constant(input_img), input_msg], training=True)\n",
    "    msg_pred = msg_model(img_pred, training=True)\n",
    "\n",
    "    original_message = round_predicted_message(target_msg)\n",
    "    predicted_message = round_predicted_message(msg_pred[0])\n",
    "    predicted_message_str = decode_binary_string(predicted_message)\n",
    "    \n",
    "    print(\"Original message as String: \", target_str)\n",
    "    print(\"Predicted message as String: \", predicted_message_str)\n",
    "    print(\"Original message in Binary: \", original_message)\n",
    "    print(\"Predicted message in Binary: \", predicted_message)\n",
    "    errors = count_errors(original_message, predicted_message)\n",
    "    print(f'Errors {errors}/{256}')\n",
    "\n",
    "    #plt.figure(figsize=(15, 15))\n",
    "    #display_list = [input_img[0], img_pred[0]]\n",
    "    #title = ['Input Image', 'Predicted Image']\n",
    "    #for i in range(2):\n",
    "    #    plt.subplot(1, 2, i+1)\n",
    "    #    plt.title(title[i])\n",
    "    #    # Getting the pixel values in the [0, 1] range to plot.\n",
    "    #    plt.imshow(display_list[i] * 0.5 + 0.5)\n",
    "    #    plt.axis('off')\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original message as String:  376c33000fe0432ab70bbb0177f5c2a7\n",
      "Predicted message as String:   \u0000\u0000\u0004 \u0001(\u0000\u0001\u0000\u0000 \u0000\u0000\u0000\u0010\u0000´\u0000\u0000\u0001\u0000\u00110\u0000\u0001`\n",
      "Original message in Binary:  0011001100110111001101100110001100110011001100110011000000110000001100000110011001100101001100000011010000110011001100100110000101100010001101110011000001100010011000100110001000110000001100010011011100110111011001100011010101100011001100100110000100110111\n",
      "Predicted message in Binary:  0010000000000000000000000000010000100000000000010010100000100001000000000000100000001000000000000000000100000000000000000010000000000000000000000000000000010000000000001011010000000000000000000000000100000000000100010011000000000000000000010110000010000000\n",
      "Errors 113/256\n"
     ]
    }
   ],
   "source": [
    "generate_images(\n",
    "    generator, \n",
    "    reader, \n",
    "    train_generator[0][0][:1], \n",
    "    msg_tensor_test[:1],\n",
    "    msg_array_test[0],\n",
    "    msg_str_test[0],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(input_image, input_msg, target_msg, step):\n",
    "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape, tf.GradientTape() as read_tape:\n",
    "        gen_output = generator([input_image, input_msg], training=True)\n",
    "\n",
    "        disc_real_output = discriminator([input_image, input_image], training=True)\n",
    "        disc_generated_output = discriminator([input_image, gen_output], training=True)\n",
    "          \n",
    "        reader_output = reader(gen_output, training=True)\n",
    "\n",
    "        gen_total_loss, gen_reader_loss, gen_gan_loss, gen_l1_loss = generator_loss(\n",
    "            disc_generated_output, \n",
    "            gen_output, \n",
    "            input_image, \n",
    "            reader_output, \n",
    "            target_msg)\n",
    "        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)\n",
    "        reader_loss = discriminator_loss(target_msg, reader_output)\n",
    "\n",
    "    generator_gradients = gen_tape.gradient(gen_total_loss,\n",
    "                                            generator.trainable_variables)\n",
    "    discriminator_gradients = disc_tape.gradient(disc_loss,\n",
    "                                                discriminator.trainable_variables)\n",
    "\t\n",
    "    reader_gradients = read_tape.gradient(\n",
    "        reader_loss,\n",
    "        reader.trainable_variables,\n",
    "    )\n",
    "\n",
    "    generator_optimizer.apply_gradients(zip(generator_gradients,\n",
    "                                            generator.trainable_variables))\n",
    "    discriminator_optimizer.apply_gradients(zip(discriminator_gradients,\n",
    "                                                discriminator.trainable_variables))\n",
    "    reader_optimizer.apply_gradients(zip(reader_gradients,\n",
    "                                        reader.trainable_variables))\n",
    "    if step == BATCH_SIZE-1:\n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar('gen_total_loss', gen_total_loss, step=step)\n",
    "            tf.summary.scalar('gen_gan_loss', gen_gan_loss, step=step)\n",
    "            tf.summary.scalar('gen_reader_loss', gen_reader_loss, step=step)\n",
    "            tf.summary.scalar('gen_l1_loss', gen_l1_loss, step=step)\n",
    "            tf.summary.scalar('disc_loss', disc_loss, step=step)\n",
    "            tf.summary.scalar('reader_loss', reader_loss, step=step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit(\n",
    "    train_img_ds, \n",
    "    train_msg_ds, \n",
    "    test_img_ds, \n",
    "    test_msg_ds, \n",
    "    current_epoch, \n",
    "    max_epoch,\n",
    ") -> None:\n",
    "    \n",
    "    for epoch in range(current_epoch, max_epoch):\n",
    "        #TRAINING\n",
    "        print(\"TRAINING EPOCH\", epoch)\n",
    "        for idx_batch in tqdm(range(len(train_img_ds))):\n",
    "            input_img = train_img_ds[idx_batch][0]\n",
    "            input_msg = train_msg_ds[idx_batch][0]\n",
    "            target_msg = train_msg_ds[idx_batch][1]\n",
    "            \n",
    "            train_step(input_img, input_msg, target_msg, idx_batch)\n",
    "    \n",
    "        #VALIDATION\n",
    "        if epoch%EVAL_STEP == 0:\n",
    "            clear_output()\n",
    "            \n",
    "            print(\"VALIDATION EPOCH\", epoch)\n",
    "            \n",
    "            \n",
    "            #saving last epoch model\n",
    "            model.save_weights(utils.get_exp_folder_last_epoch(), save_format='tf')\n",
    "        \n",
    "            #valid with set 1\n",
    "            print(\"Validation set\")\n",
    "            psnr_1, nrmse_1, mse_1 = valid_step(valid_x_1, valid_y_1, num_val_minibatches, mini_batch_size)\n",
    "            \n",
    "            #valid with set 2\n",
    "            #print(\"Validation set 2\")\n",
    "            #psnr_2, nrmse_2, mse_2 = valid_step(valid_x_2, valid_y_2, num_val_minibatches, mini_batch_size)\n",
    "            psnr_2, nrmse_2, mse_2 = 0, 0, 0\n",
    "            \n",
    "            #valid with set 3\n",
    "            #print(\"Validation set 3\")\n",
    "            #psnr_3, nrmse_3, mse_3 = valid_step(valid_x_3, valid_y_3, num_val_minibatches, mini_batch_size)\n",
    "            psnr_3, nrmse_3, mse_3 = 0, 0, 0\n",
    "            \n",
    "            utils.update_chart_data(epoch=epoch, train_mse=train_loss.result().numpy(), \n",
    "                                    valid_mse=[mse_1,mse_2,mse_3], psnr=[psnr_1,psnr_2,psnr_3], nrmse=[nrmse_1,nrmse_2, nrmse_3])\n",
    "            utils.draw_chart()\n",
    "            \n",
    "            #saving best validation model\n",
    "            if psnr_1 > BEST_VALIDATION:\n",
    "                BEST_VALIDATION = psnr_1\n",
    "                model.save_weights(utils.get_exp_folder_best_valid(), save_format='tf')\n",
    "        \n",
    "    train_loss.reset_states()\n",
    "    \n",
    "    example_input, example_target = next(iter(test_ds.take(1)))\n",
    "    start = time.time()\n",
    "    \n",
    "    for step, (input_image, target) in train_ds.repeat().take(steps).enumerate():\n",
    "        if (step) % 1000 == 0:\n",
    "            display.clear_output(wait=True)\n",
    "\n",
    "            if step != 0:\n",
    "                print(f'Time taken for 1000 steps: {time.time()-start:.2f} sec\\n')\n",
    "\n",
    "            start = time.time()\n",
    "\n",
    "            generate_images(generator, example_input, example_target)\n",
    "            print(f\"Step: {step//1000}k\")\n",
    "\n",
    "        train_step(input_image, target, step)\n",
    "\n",
    "        # Training step\n",
    "        if (step+1) % 10 == 0:\n",
    "            print('.', end='', flush=True)\n",
    "\n",
    "\n",
    "    # Save (checkpoint) the model every 5k steps\n",
    "        if (step + 1) % 5000 == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ghost_sign",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
